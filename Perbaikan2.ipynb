{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ebf5d6-37ff-4e2a-9585-f9f29606e92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      " [[ 63.    1.    3.  145.  233.    1.    0.  150.    0.    2.3   0.    0.\n",
      "    1.    1. ]\n",
      " [ 37.    1.    2.  130.  250.    0.    1.  187.    0.    3.5   0.    0.\n",
      "    2.    1. ]\n",
      " [ 41.    0.    1.  130.  204.    0.    0.  172.    0.    1.4   2.    0.\n",
      "    2.    1. ]\n",
      " [ 56.    1.    1.  120.  236.    0.    1.  178.    0.    0.8   2.    0.\n",
      "    2.    1. ]\n",
      " [ 57.    0.    0.  120.  354.    0.    1.  163.    1.    0.6   2.    0.\n",
      "    2.    1. ]]\n",
      "X_train shape: (13, 100)\n",
      "y_train shape: (1, 100)\n",
      "Iteration 0, Loss: 0.00409370762902724\n",
      "Iteration 100, Loss: 0.0040754333223413\n",
      "Iteration 200, Loss: 0.004057321117493684\n",
      "Iteration 300, Loss: 0.004039368869989882\n",
      "Iteration 400, Loss: 0.0040215744729586705\n",
      "Iteration 500, Loss: 0.00400393585633059\n",
      "Iteration 600, Loss: 0.00398645098604046\n",
      "Iteration 700, Loss: 0.003969117863246071\n",
      "Iteration 800, Loss: 0.003951934523571808\n",
      "Iteration 900, Loss: 0.00393489903636842\n",
      "Iteration 1000, Loss: 0.00391800950399325\n",
      "Iteration 1100, Loss: 0.003901264061107837\n",
      "Iteration 1200, Loss: 0.0038846608739950606\n",
      "Iteration 1300, Loss: 0.0038681981398909593\n",
      "Iteration 1400, Loss: 0.0038518740863365663\n",
      "Iteration 1500, Loss: 0.00383568697054246\n",
      "Iteration 1600, Loss: 0.0038196350787724617\n",
      "Iteration 1700, Loss: 0.0038037167257408177\n",
      "Iteration 1800, Loss: 0.0037879302540237054\n",
      "Iteration 1900, Loss: 0.003772274033488024\n",
      "Training selesai.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "\n",
    "# Load data\n",
    "train_data = np.loadtxt('train.csv', delimiter=',')\n",
    "print(\"Train Data:\\n\", train_data[:5])\n",
    "\n",
    "# Pisahkan fitur dan label pada data training\n",
    "X_train = train_data[:, :-1]  # Semua kolom kecuali kolom terakhir (fitur)\n",
    "y_train = train_data[:, -1]   # Kolom terakhir (label)\n",
    "\n",
    "# Transpose X_train untuk memudahkan perhitungan\n",
    "X_train = X_train.T\n",
    "y_train = y_train.reshape((1, -1))  # Ubah y_train menjadi bentuk (1, jumlah sampel)\n",
    "\n",
    "# Periksa bentuk data\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Bobot dan bias untuk input layer ke hidden layer 1 (13 fitur ke 20 neuron)\n",
    "w1 = np.random.rand(20, 13)\n",
    "b1 = np.zeros((20, 1))\n",
    "\n",
    "# Bobot dan bias untuk hidden layer 1 ke hidden layer 2 (20 neuron ke 10 neuron)\n",
    "w2 = np.random.rand(10, 20)\n",
    "b2 = np.zeros((10, 1))\n",
    "\n",
    "# Bobot dan bias untuk hidden layer 2 ke output layer (10 neuron ke 1 output)\n",
    "w3 = np.random.rand(1, 10)\n",
    "b3 = np.zeros((1, 1))\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Inisialisasi learning rate\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Training loop\n",
    "for i in range(2000):\n",
    "    # Layer input ke hidden layer 1\n",
    "    z1 = np.dot(w1, X_train) + b1  # (20, 13) * (13, 100) -> (20, 100)\n",
    "    a1 = sigmoid(z1)  # Output layer 1 (20, 100)\n",
    "\n",
    "    # Hidden layer 1 ke hidden layer 2\n",
    "    z2 = np.dot(w2, a1) + b2  # (10, 20) * (20, 100) -> (10, 100)\n",
    "    a2 = sigmoid(z2)  # Output layer 2 (10, 100)\n",
    "\n",
    "    # Hidden layer 2 ke output layer\n",
    "    z3 = np.dot(w3, a2) + b3  # (1, 10) * (10, 100) -> (1, 100)\n",
    "    a3 = sigmoid(z3)  # Output layer (1, 100)\n",
    "\n",
    "    # Prediksi (output)\n",
    "    yhat = a3\n",
    "\n",
    "    # Loss function (Binary Cross-Entropy Loss)\n",
    "    L = -y_train * np.log(yhat) - (1 - y_train) * np.log(1 - yhat)\n",
    "    m = y_train.shape[1]  # Jumlah sampel\n",
    "    J = (1 / m) * np.sum(L)\n",
    "\n",
    "    # Backpropagation\n",
    "    dz3 = a3 - y_train  # (1, 100)\n",
    "\n",
    "    # Gradien error di hidden layer 2\n",
    "    dz2 = np.dot(w3.T, dz3) * a2 * (1 - a2)  # (10, 100)\n",
    "\n",
    "    # Gradien error di hidden layer 1\n",
    "    dz1 = np.dot(w2.T, dz2) * a1 * (1 - a1)  # (20, 100)\n",
    "\n",
    "    # Update bobot dan bias\n",
    "    w3 -= learning_rate * np.dot(dz3, a2.T) / m  # (1, 100) * (100, 10) -> (1, 10)\n",
    "    b3 -= learning_rate * np.sum(dz3, axis=1, keepdims=True) / m  # (1, 1)\n",
    "\n",
    "    w2 -= learning_rate * np.dot(dz2, a1.T) / m  # (10, 100) * (100, 20) -> (10, 20)\n",
    "    b2 -= learning_rate * np.sum(dz2, axis=1, keepdims=True) / m  # (10, 1)\n",
    "\n",
    "    w1 -= learning_rate * np.dot(dz1, X_train.T) / m  # (20, 100) * (100, 13) -> (20, 13)\n",
    "    b1 -= learning_rate * np.sum(dz1, axis=1, keepdims=True) / m  # (20, 1)\n",
    "\n",
    "    # Print loss setiap 100 iterasi\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Iteration {i}, Loss: {J}\")\n",
    "\n",
    "# Print hasil setelah training selesai\n",
    "print(\"Training selesai.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eadbb27-dca1-4830-b7a7-3cac25ddcaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296,\n",
       "        0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296,\n",
       "        0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296,\n",
       "        0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296,\n",
       "        0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296,\n",
       "        0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296,\n",
       "        0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296,\n",
       "        0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296,\n",
       "        0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296,\n",
       "        0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296,\n",
       "        0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296,\n",
       "        0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296,\n",
       "        0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296,\n",
       "        0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296,\n",
       "        0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296,\n",
       "        0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296,\n",
       "        0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296,\n",
       "        0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296,\n",
       "        0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296,\n",
       "        0.99053296, 0.99053296, 0.99053296, 0.99053296, 0.99053296]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4efc5a-a0e4-47de-875a-919c42d5bdf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
