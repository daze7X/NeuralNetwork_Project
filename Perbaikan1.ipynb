{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "041b3fe3-8681-43d0-829a-d4986c75cae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (13, 100)\n",
      "y_train shape: (1, 100)\n",
      "X_test shape: (13, 25)\n",
      "y_test shape: (1, 25)\n",
      "Iteration 0, Loss: 0.009429404848753774\n",
      "Iteration 100, Loss: 0.009333507244688875\n",
      "Iteration 200, Loss: 0.009239531801452901\n",
      "Iteration 300, Loss: 0.009147421472877141\n",
      "Iteration 400, Loss: 0.009057121443051926\n",
      "Iteration 500, Loss: 0.008968579018579087\n",
      "Iteration 600, Loss: 0.008881743527007073\n",
      "Iteration 700, Loss: 0.008796566221030337\n",
      "Iteration 800, Loss: 0.008713000188079535\n",
      "Iteration 900, Loss: 0.008631000264956445\n",
      "Iteration 1000, Loss: 0.008550522957177705\n",
      "Iteration 1100, Loss: 0.008471526362739942\n",
      "Iteration 1200, Loss: 0.008393970100017937\n",
      "Iteration 1300, Loss: 0.008317815239538933\n",
      "Iteration 1400, Loss: 0.008243024239395757\n",
      "Iteration 1500, Loss: 0.008169560884069654\n",
      "Iteration 1600, Loss: 0.008097390226458515\n",
      "Iteration 1700, Loss: 0.008026478532915457\n",
      "Iteration 1800, Loss: 0.007956793231114949\n",
      "Iteration 1900, Loss: 0.007888302860583484\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "\n",
    "# Load data\n",
    "train_data = np.loadtxt('train.csv', delimiter=',')\n",
    "test_data = np.loadtxt('test.csv', delimiter=',')\n",
    "\n",
    "# Pisahkan fitur dan label pada data training\n",
    "X_train = train_data[:, :-1]  # Semua kolom kecuali kolom terakhir (fitur)\n",
    "y_train = train_data[:, -1]   # Kolom terakhir (label)\n",
    "\n",
    "# Pisahkan fitur dan label pada data test\n",
    "X_test = test_data[:, :-1]  # Semua kolom kecuali kolom terakhir (fitur)\n",
    "y_test = test_data[:, -1]   # Kolom terakhir (label)\n",
    "\n",
    "# Transpose data untuk input layer (13, 100) agar sesuai dengan bentuk bobot\n",
    "X_train = X_train.T  # (13, 100)\n",
    "y_train = y_train.reshape(1, -1)  # (1, 100)\n",
    "\n",
    "X_test = X_test.T  # (13, 25)\n",
    "y_test = y_test.reshape(1, -1)  # (1, 25)\n",
    "\n",
    "# Periksa bentuk data\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Bobot dan bias untuk input layer ke hidden layer 1 (13 fitur ke 20 neuron)\n",
    "w1 = np.random.rand(20, 13)  # (jumlah neuron layer 1, jumlah fitur input)\n",
    "b1 = np.zeros((20, 1))  # Bias untuk layer 1 (20, 1)\n",
    "\n",
    "# Bobot dan bias untuk hidden layer 1 ke hidden layer 2 (20 neuron ke 10 neuron)\n",
    "w2 = np.random.rand(10, 20)  # (jumlah neuron layer 2, jumlah neuron layer 1)\n",
    "b2 = np.zeros((10, 1))  # Bias untuk layer 2 (10, 1)\n",
    "\n",
    "# Bobot dan bias untuk hidden layer 2 ke output layer (10 neuron ke 1 output)\n",
    "w3 = np.random.rand(1, 10)  # (jumlah neuron output, jumlah neuron layer 2)\n",
    "b3 = np.zeros((1, 1))  # Bias untuk layer output (1, 1)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Inisialisasi variabel\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Feedforward loop\n",
    "for i in range(2000):\n",
    "    # Layer input ke hidden layer 1\n",
    "    z1 = np.dot(w1, X_train) + b1  # (20, 13) * (13, 100) -> (20, 100)\n",
    "    a1 = sigmoid(z1)  # Output layer 1 (20, 100)\n",
    "\n",
    "    z2 = np.dot(w2, a1) + b2  # (10, 20) * (20, 100) -> (10, 100)\n",
    "    a2 = sigmoid(z2)  # Output layer 2 (10, 100)\n",
    "\n",
    "    z3 = np.dot(w3, a2) + b3  # (1, 10) * (10, 100) -> (1, 100)\n",
    "    a3 = sigmoid(z3)  # Output layer (1, 100)\n",
    "\n",
    "    yhat = a3  # Prediksi output\n",
    "\n",
    "    # Fungsi loss (Binary Cross-Entropy Loss)\n",
    "    L = -y_train * np.log(yhat) - (1 - y_train) * np.log(1 - yhat)\n",
    "\n",
    "    # Rata-rata loss\n",
    "    m = y_train.shape[1]  # Jumlah sampel\n",
    "    J = (1 / m) * np.sum(L)\n",
    "\n",
    "    # Print loss setiap 100 iterasi\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Iteration {i}, Loss: {J}\")\n",
    "\n",
    "    # Backpropagation\n",
    "    dz3 = a3 - y_train  # (1, 100)\n",
    "    dz2 = np.dot(w3.T, dz3) * a2 * (1 - a2)  # (10, 100)\n",
    "    dz1 = np.dot(w2.T, dz2) * a1 * (1 - a1)  # (20, 100)\n",
    "\n",
    "    # Update bobot dan bias\n",
    "    w3 -= learning_rate * np.dot(dz3, a2.T) / m  # (1, 10) * (10, 100)\n",
    "    b3 -= learning_rate * np.sum(dz3, axis=1, keepdims=True) / m  # (1, 1)\n",
    "\n",
    "    w2 -= learning_rate * np.dot(dz2, a1.T) / m  # (10, 20) * (20, 100)\n",
    "    b2 -= learning_rate * np.sum(dz2, axis=1, keepdims=True) / m  # (10, 1)\n",
    "\n",
    "    w1 -= learning_rate * np.dot(dz1, X_train.T) / m  # (20, 13) * (13, 100)\n",
    "    b1 -= learning_rate * np.sum(dz1, axis=1, keepdims=True) / m  # (20, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a36fe7-a349-4d52-9ce3-b4dc33963d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886,\n",
       "        0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886,\n",
       "        0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886,\n",
       "        0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886,\n",
       "        0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886,\n",
       "        0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886,\n",
       "        0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886,\n",
       "        0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886,\n",
       "        0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886,\n",
       "        0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886,\n",
       "        0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886,\n",
       "        0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886,\n",
       "        0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886,\n",
       "        0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886,\n",
       "        0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886,\n",
       "        0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886,\n",
       "        0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886,\n",
       "        0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886,\n",
       "        0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886,\n",
       "        0.99220886, 0.99220886, 0.99220886, 0.99220886, 0.99220886]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaf44a1-a305-4655-b3f6-e1ef611eb363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
